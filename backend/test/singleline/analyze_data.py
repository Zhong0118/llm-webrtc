# analyze_data.py
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import numpy as np

BATCH_SIZES = [1, 5, 10, 20]

def ensure_dir(directory):
    if not os.path.exists(directory):
        os.makedirs(directory)

def plot_cdf(data, column, ax, label):
    """è¾…åŠ©å‡½æ•°ï¼šç»˜åˆ¶ç´¯ç§¯åˆ†å¸ƒå‡½æ•° (CDF)"""
    sorted_data = np.sort(data[column])
    yvals = np.arange(len(sorted_data)) / float(len(sorted_data) - 1)
    ax.plot(sorted_data, yvals, label=label)

def analyze_single_file(batch_size):
    filename = f'benchmark_log_batch_{batch_size}.csv'
    
    if not os.path.exists(filename):
        print(f"âš ï¸ è·³è¿‡: æ‰¾ä¸åˆ° {filename}")
        return

    print(f"\nğŸ“Š æ­£åœ¨åˆ†æ: {filename} ...")
    df = pd.read_csv(filename)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = os.path.join("analysis_results", f"batch_{batch_size}")
    ensure_dir(output_dir)
    
    # è®¾ç½®ç»˜å›¾é£æ ¼
    sns.set_theme(style="whitegrid", context="notebook")
    
    # ================= å›¾è¡¨ 1: æ¨ç†è€—æ—¶åˆ†å¸ƒ (Boxplot) =================
    # ä¸åŒå¸§æ•°å’Œåˆ†è¾¨ç‡ä¸‹çš„æ¨ç†æ—¶é—´å¯¹æ¯”ã€‚ç®±å­é«˜è¯´æ˜æ¨ç†æ…¢ï¼Œé•¿è¯´æ˜æ€§èƒ½ä¸ç¨³å®š
    plt.figure(figsize=(10, 6))
    sns.boxplot(x='fps', y='inference_time', hue='resolution', data=df, palette="Set2")
    plt.title(f"AI Model Inference Latency (Batch: {batch_size})")
    plt.ylabel("Time (ms)")
    plt.xlabel("Target FPS")
    plt.savefig(os.path.join(output_dir, "1_inference_latency.png"))
    plt.close()

    # ================= å›¾è¡¨ 2: E2E å»¶è¿Ÿç¨³å®šæ€§ (Lineplot) =================
    # æ˜¯å¹³çš„é‚£å°±ç¨³å®šï¼Œå‘ä¸Šå€¾æ–œè¯´æ˜å‘ç”Ÿç§¯å‹
    plt.figure(figsize=(12, 6))
    sns.lineplot(x=df.index, y='e2e_delay', hue='fps', style='resolution', data=df, alpha=0.8, palette="tab10")
    plt.title(f"End-to-End Latency Stability (Batch: {batch_size})")
    plt.ylabel("Latency (ms)")
    plt.xlabel("Sample Sequence")
    plt.ylim(bottom=0)
    plt.savefig(os.path.join(output_dir, "2_e2e_stability.png"))
    plt.close()

    # ================= å›¾è¡¨ 3: FPS è¾¾æ ‡ç‡åˆ†æ (Barplot) =================
    # å¯¹æ¯” "è®¾ç½®çš„ FPS" å’Œ "æœåŠ¡å™¨å®é™…å¤„ç† FPS"
    plt.figure(figsize=(10, 6))
    # èåŒ–æ•°æ®ä»¥ä¾¿ç»˜å›¾
    fps_df = df.melt(id_vars=['resolution', 'fps'], value_vars=['server_fps'], var_name='metric', value_name='value')
    sns.barplot(x='fps', y='value', hue='resolution', data=fps_df, palette="viridis")
    # ç”»ä¸€æ¡ç†æƒ³çº¿
    plt.plot([-0.5, 3.5], [15, 15], 'r--', alpha=0.5, label='Target 15')
    plt.plot([-0.5, 3.5], [30, 30], 'r:', alpha=0.5, label='Target 30')
    plt.title(f"Server Actual Throughput (FPS) vs Target")
    plt.ylabel("Actual FPS")
    plt.ylim(0, 35)
    plt.savefig(os.path.join(output_dir, "3_fps_performance.png"))
    plt.close()

    # ================= å›¾è¡¨ 4: å»¶è¿Ÿæ„æˆåˆ†æ (Network vs Compute) =================
    # çº¢è‰²æ˜¯AIçš„è®¡ç®—é€Ÿåº¦ï¼Œè“è‰²æ˜¯è§£ç ç¼–ç ç­‰æ‚é¡¹ï¼Œç»¿è‰²æ˜¯ç½‘ç»œå»¶è¿Ÿï¼ˆä¼°ç®—ï¼‰
    df['network_overhead'] = df['e2e_delay'] - df['process_time']
    df['network_overhead'] = df['network_overhead'].clip(lower=0) # ä¿®æ­£è´Ÿæ•°å™ªéŸ³
    
    # å–å‡å€¼ç»˜å›¾
    avg_data = df.groupby(['resolution', 'fps']).mean().reset_index()
    
    fig, ax = plt.subplots(figsize=(10, 6))
    x = range(len(avg_data))
    labels = [f"{r}\n@{f}fps" for r, f in zip(avg_data['resolution'], avg_data['fps'])]
    
    # å †å æŸ±çŠ¶å›¾ï¼šæœ€åº•ä¸‹æ˜¯æ¨ç†ï¼Œä¸­é—´æ˜¯å¤„ç†æ‚é¡¹ï¼Œæœ€ä¸Šé¢æ˜¯ç½‘ç»œ
    p1 = plt.bar(x, avg_data['inference_time'], label='AI Inference (GPU)', color='#ff9999')
    p2 = plt.bar(x, avg_data['process_time'] - avg_data['inference_time'], bottom=avg_data['inference_time'], label='Decode/Encode (CPU)', color='#66b3ff')
    p3 = plt.bar(x, avg_data['network_overhead'], bottom=avg_data['process_time'], label='Network RTT (Est.)', color='#99ff99')
    
    plt.xticks(x, labels)
    plt.ylabel("Latency (ms)")
    plt.title("Latency Composition Breakdown")
    plt.legend()
    plt.savefig(os.path.join(output_dir, "4_latency_composition.png"))
    plt.close()

    # ================= å›¾è¡¨ 5: è´Ÿè½½å½±å“ (æ•£ç‚¹å›¾) =================
    # çœ‹çœ‹ç”»é¢é‡Œäººè¶Šå¤šï¼Œæ¨ç†æ˜¯ä¸æ˜¯è¶Šæ…¢ï¼Ÿ
    plt.figure(figsize=(10, 6))
    sns.scatterplot(x='object_count', y='inference_time', hue='resolution', style='fps', data=df, s=100)
    plt.title("Impact of Object Count on Inference Speed")
    plt.xlabel("Detected Objects Count")
    plt.ylabel("Inference Time (ms)")
    plt.savefig(os.path.join(output_dir, "5_load_impact.png"))
    plt.close()

    # ================= å›¾è¡¨ 6: å»¶è¿Ÿåˆ†å¸ƒ CDF (ç´¯ç§¯åˆ†å¸ƒ) =================
    # å›ç­”ç™¾åˆ†ä¹‹å¤šå°‘çš„æ ·æœ¬ä¹‹ä¸‹çš„å»¶è¿Ÿï¼Œçœ‹æ˜¯å¦è¾¾æ ‡
    fig, ax = plt.subplots(figsize=(10, 6))
    for name, group in df.groupby(['resolution', 'fps']):
        label = f"{name[0]} @ {name[1]}fps"
        plot_cdf(group, 'e2e_delay', ax, label)
    
    plt.title("Latency CDF (Cumulative Distribution Function)")
    plt.xlabel("Latency (ms)")
    plt.ylabel("Probability")
    plt.grid(True, which='both', linestyle='--', alpha=0.7)
    plt.legend()
    plt.savefig(os.path.join(output_dir, "6_latency_cdf.png"))
    plt.close()

    print(f"âœ… [Batch {batch_size}] 6å¼ å›¾è¡¨å·²ä¿å­˜è‡³: {output_dir}")

def main():
    print("ğŸš€ å¼€å§‹ç”Ÿæˆæ·±åº¦åˆ†æå›¾è¡¨...")
    if not os.path.exists("analysis_results"):
        os.makedirs("analysis_results")
        
    for size in BATCH_SIZES:
        analyze_single_file(size)
    print("\nğŸ‰ å…¨éƒ¨å›¾è¡¨ç”Ÿæˆå®Œæ¯•ï¼è¯·æŸ¥çœ‹ analysis_results æ–‡ä»¶å¤¹ã€‚")

if __name__ == "__main__":
    main()
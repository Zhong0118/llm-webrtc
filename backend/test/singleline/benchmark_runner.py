# benchmark_runner.py
import asyncio
import time
import uuid
import logging
import os
import av
import pandas as pd
import socketio
from aiortc import RTCPeerConnection, RTCSessionDescription, VideoStreamTrack

# ================= é…ç½®åŒºåŸŸ =================
VIDEO_FILE = "part1.mp4" 
SERVER_URL = "https://localhost:33335" # 

# [æ ¸å¿ƒ] å®šä¹‰å››ç»„èšåˆçª—å£å¤§å°
BATCH_SIZES = [1, 5, 10, 20]

# æµ‹è¯•é…ç½®çŸ©é˜µ (æ¯ä¸ªBatchSizeéƒ½ä¼šè·‘ä¸€éè¿™ç»„é…ç½®)
CONFIGS = [
    {"res": (640, 480), "fps": 10, "duration": 20},
    {"res": (640, 480), "fps": 15, "duration": 20},
    {"res": (640, 480), "fps": 20, "duration": 20},
    {"res": (640, 480), "fps": 30, "duration": 20},
    {"res": (1280, 720), "fps": 10, "duration": 20},
    {"res": (1280, 720), "fps": 15, "duration": 20},
    {"res": (1280, 720), "fps": 20, "duration": 20},
    {"res": (1280, 720), "fps": 30, "duration": 20},
]

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("Benchmark")
logging.getLogger("aioice.ice").setLevel(logging.ERROR)

class FileVideoTrack(VideoStreamTrack):
    def __init__(self, file_path, target_fps):
        super().__init__()
        self.container = av.open(file_path)
        self.stream = self.container.streams.video[0]
        self.target_fps = target_fps
        self.interval = 1 / target_fps
        self.iter = self.container.decode(self.stream)
        self.last_time = 0

    # é™é€Ÿè¯»å–æœ¬åœ°è§†é¢‘ï¼Œå¾ªç¯æ’­æ”¾
    async def recv(self):  
        now = time.time()
        wait = self.last_time + self.interval - now
        if wait > 0:
            await asyncio.sleep(wait)
        self.last_time = time.time()
        try:
            frame = next(self.iter)
        except StopIteration:
            self.container.seek(0)
            self.iter = self.container.decode(self.stream)
            frame = next(self.iter)
        pts, time_base = await self.next_timestamp()
        frame.pts = pts
        frame.time_base = time_base
        return frame

class BenchmarkClient:
    def __init__(self, config, batch_size):
        self.config = config
        self.batch_size = batch_size # [æ–°å¢] æ¥æ”¶å½“å‰æ‰¹æ¬¡å¤§å°
        self.sio = socketio.AsyncClient(ssl_verify=False) # å¿½ç•¥SSLéªŒè¯æ–¹ä¾¿æœ¬åœ°æµ‹è¯•
        self.pc = RTCPeerConnection()
        self.room_id = f"bench_{uuid.uuid4().hex[:4]}"
        self.peer_id = f"client_{uuid.uuid4().hex[:4]}"
        self.results = []
        self.running = False
        self.batch_buffer = [] 

# è¿æ¥ Socket.IOï¼Œå‘ WebRTC offerï¼Œè¿è¡ŒæŒ‡å®šç§’æ•°ï¼ŒæœŸé—´ç”±äº‹ä»¶å›è°ƒæŒç»­æ”’æ•°æ®ã€‚
    async def run(self):
        logger.info(f"   -> Testing: {self.config['res']} @ {self.config['fps']} FPS")
        self._bind_socket_events()
        try:
            await self.sio.connect(SERVER_URL, namespaces=['/p2p', '/ai_analysis'])
        except Exception as e:
            logger.error(f"Connection failed: {e}")
            return []

        self.running = True
        await self.sio.emit('join', {'roomId': self.room_id, 'peerId': self.peer_id}, namespace='/ai_analysis')
        
        track = FileVideoTrack(VIDEO_FILE, self.config['fps'])
        self.pc.addTrack(track)
        
        offer = await self.pc.createOffer()
        await self.pc.setLocalDescription(offer)
        
        await self.sio.emit('offer', {
            'offer': {'sdp': offer.sdp, 'type': offer.type},
            'roomId': self.room_id,
            'peerId': self.peer_id
        }, namespace='/ai_analysis')

        start_time = time.time()
        while time.time() - start_time < self.config['duration']:
            if not self.running: break
            await asyncio.sleep(1)
            
        await self.cleanup()
        return self.results


    def _bind_socket_events(self):
        # è¿™æ˜¯æ”¶åˆ°æœåŠ¡å™¨ AI ç»“æœçš„å›è°ƒã€‚
        @self.sio.on('ai_result', namespace='/ai_analysis')
        async def on_ai_result(data):
            if not self.running: return
            
            recv_time = time.time()
            send_time_ms = data.get('send_time')
            if send_time_ms is None:
                # å…¼å®¹æ—§å­—æ®µï¼ˆRTP æ—¶é—´æˆ³ï¼‰
                send_time_ms = data.get('timestamp', recv_time * 1000)
            # è®¡ç®—ç«¯åˆ°ç«¯å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
            e2e_delay = (recv_time * 1000) - send_time_ms
            
            raw_record = {
                "server_fps": data.get('fps', 0),
                "inference_time": data.get('inference_time', 0),
                "process_time": data.get('process_time', 0),
                "e2e_delay": max(0, e2e_delay),
                "object_count": len(data.get('objects', [])),
                "frame_id": data['frame_id']
            }
            
            self.batch_buffer.append(raw_record)
            # ç¼“å†²ï¼šå®ƒä¸ç›´æ¥å†™å…¥ç»“æœï¼Œè€Œæ˜¯æŠŠæ•°æ®å¡è¿› batch_bufferã€‚
            # [æ ¸å¿ƒ] æ ¹æ®ä¼ å…¥çš„ batch_size è¿›è¡Œèšåˆ
            if len(self.batch_buffer) >= self.batch_size:
                self._flush_buffer()

        @self.sio.on('answer', namespace='/ai_analysis')
        async def on_answer(data):
            desc = RTCSessionDescription(sdp=data['answer']['sdp'], type=data['answer']['type'])
            await self.pc.setRemoteDescription(desc)

# ç›®çš„ï¼šæ¶ˆé™¤ç½‘ç»œç¬é—´æŠ–åŠ¨å¯¹æ•´ä½“è¶‹åŠ¿çš„å½±å“ï¼Œè¾“å‡ºä¸€æ¡ä»£è¡¨æ€§çš„æ•°æ®ã€‚å®ƒæŠŠç¼“å†²åŒºé‡Œçš„ 10 å¸§æ•°æ®æ‹¿å‡ºæ¥ï¼Œæ±‚å¹³å‡å€¼ (mean)ã€‚
    def _flush_buffer(self):
        if not self.batch_buffer: return
        count = len(self.batch_buffer)
        
        # server_fps: æœåŠ¡å™¨å®é™…å¤„ç†èƒ½åŠ›ï¼ˆçœ‹æ˜¯å¦è·‘æ»¡ï¼‰ã€‚
        # inference_time: YOLO çº¯æ¨ç†è€—æ—¶ï¼ˆæ˜¾å¡èƒ½åŠ›ï¼‰ã€‚
        # process_time: è§£ç +æ¨ç†+ç¼–ç æ€»è€—æ—¶ï¼ˆåç«¯æ•ˆç‡ï¼‰ã€‚
        # e2e_delay: ç«¯åˆ°ç«¯å»¶è¿Ÿï¼ˆç”¨æˆ·ä½“éªŒï¼‰ã€‚
        avg_record = {
            "resolution": f"{self.config['res'][0]}x{self.config['res'][1]}",
            "fps": self.config['fps'],
            "batch_size_group": self.batch_size, # æ ‡è®°å±äºå“ªä¸€ç»„
            "end_frame_id": self.batch_buffer[-1]['frame_id'],
            "server_fps": round(sum(d['server_fps'] for d in self.batch_buffer) / count, 2),
            "inference_time": round(sum(d['inference_time'] for d in self.batch_buffer) / count, 2),
            "process_time": round(sum(d['process_time'] for d in self.batch_buffer) / count, 2),
            "e2e_delay": round(sum(d['e2e_delay'] for d in self.batch_buffer) / count, 2),
            "object_count": round(sum(d['object_count'] for d in self.batch_buffer) / count, 2)
        }
        self.results.append(avg_record)
        self.batch_buffer = []

    async def cleanup(self):
        self.running = False
        if self.batch_buffer: self._flush_buffer()
        if self.pc: await self.pc.close()
        if self.sio.connected: await self.sio.disconnect()

async def main():
    if not os.path.exists(VIDEO_FILE):
        logger.error(f"Video file not found: {VIDEO_FILE}")
        return

    # [æ ¸å¿ƒå¾ªç¯] éå† 4 ç»„ batch_size
    for batch_size in BATCH_SIZES:
        logger.info(f"\n\n========== å¼€å§‹æµ‹è¯• Batch Size: {batch_size} ==========")
        current_batch_data = []
        
        for conf in CONFIGS:
            # å°† batch_size ä¼ å…¥ Client
            client = BenchmarkClient(conf, batch_size)
            data = await client.run()
            current_batch_data.extend(data)
            await asyncio.sleep(1) # ä¼‘æ¯ä¸€ä¸‹ï¼Œé¿å…ç«¯å£å†²çª
        
        # æ¯è·‘å®Œä¸€ç»„ï¼Œå­˜ä¸€ä¸ª CSV
        filename = f"benchmark_log_batch_{batch_size}.csv"
        if current_batch_data:
            df = pd.DataFrame(current_batch_data)
            df.to_csv(filename, index=False)
            logger.info(f"âœ… Saved: {filename} (Rows: {len(df)})")
        else:
            logger.warning(f"âŒ No data collected for batch {batch_size}")

    logger.info("\nğŸ‰ æ‰€æœ‰æµ‹è¯•ç»„è¿è¡Œå®Œæ¯•ï¼")

if __name__ == "__main__":
    asyncio.run(main())
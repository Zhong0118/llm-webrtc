# backend/ai_processor.py (ç§‘ç ”å‡çº§ç‰ˆ)
import time
import logging
import numpy as np
from collections import deque
import torch
from ultralytics import YOLO
import random

logger = logging.getLogger("AIProcessor")

class AIProcessor:
    def __init__(self):
        self.frame_count = 0
        
        # 1. æ¨¡å‹åŠ è½½ (YOLO ä»…ä½œæ¼”ç¤ºï¼Œå®é™…å¯æ›¿æ¢ä¸ºæ‰‹è¯­æ¨¡å‹)
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        logger.info(f"ğŸš€ Loading model on {self.device}...")
        self.model = YOLO('yolov8n.pt') 
        self.model.to(self.device)

        # 2. [ç§‘ç ”æ ¸å¿ƒ] åŠ¨æ€é…ç½®å‚æ•°
        # è¿™äº›å‚æ•°ç°åœ¨å¯ä»¥é€šè¿‡å‰ç«¯æˆ–æµ‹è¯•è„šæœ¬åŠ¨æ€ä¿®æ”¹ï¼Œä¸ç”¨é‡å¯æœåŠ¡å™¨
        self.config = {
            "chunk_size": 1,      # é»˜è®¤å•å¸§ (å®æ—¶)
            "stride": 1,          # æ­¥é•¿
            "simulate_drift": 80   # æ¨¡æ‹Ÿé¢å¤–è€—æ—¶
        }
        
        # æ—¶åºç¼“å†²åŒº
        self.chunk_buffer = deque(maxlen=30) 
        self.timestamp_buffer = deque(maxlen=30)
        self.pts_buffer = deque(maxlen=30)
        self.last_infer_time = 0

    def update_config(self, new_config):
        """ä¾›æµ‹è¯•è„šæœ¬åŠ¨æ€è°ƒæ•´å®éªŒå‚æ•°"""
        self.config.update(new_config)
        # é‡ç½®ç¼“å†²åŒºä»¥é€‚åº”æ–°é…ç½®
        self.chunk_buffer.clear()
        self.timestamp_buffer.clear()
        self.pts_buffer.clear()
        logger.info(f"ğŸ§ª å®éªŒå‚æ•°æ›´æ–°: {self.config}")

    def warmup(self):
        """
        é¢„çƒ­
        æ‰§è¡Œä¸€æ¬¡ç©ºæ¨ç†ï¼Œå®Œæˆ CUDA åˆå§‹åŒ–ã€æ˜¾å­˜ç”³è¯·å’Œ JIT ç¼–è¯‘ã€‚
        è§£å†³ 'é¦–å¸§å»¶è¿Ÿ 7ç§’' çš„é—®é¢˜ã€‚
        """
        logger.info(f"ğŸ”¥ AI Engine Warming up on {self.device}...")
        try:
            # åˆ›å»ºä¸€ä¸ª 640x640 çš„å…¨é»‘ dummy frame
            dummy_input = np.zeros((640, 640, 3), dtype=np.uint8)
            # æ‰§è¡Œä¸€æ¬¡æ¨ç† (è¿™æ¬¡ä¼šå¾ˆæ…¢)
            self.model(dummy_input, verbose=False)
            logger.info("âœ… AI Engine Ready! (Warmup completed)")
        except Exception as e:
            logger.error(f"âŒ Warmup failed: {e}")
            return False
        return True

    def _apply_simulated_delay(self):
        """åœ¨æ¨ç†åæ³¨å…¥é¢å¤–å»¶è¿Ÿï¼Œä¾¿äºæ¨¡æ‹Ÿé«˜è´Ÿè½½åœºæ™¯"""
        simulate_delay_ms = max(0, self.config.get("simulate_drift", 0))
        if simulate_delay_ms:
            time.sleep(simulate_delay_ms / 1000.0)
        return simulate_delay_ms

    def process(self, frame, pts, time_base):
        """
        1. è¾“å…¥å¢åŠ äº† pts (RTPæ—¶é—´æˆ³) å’Œ time_base (æ—¶é—´åŸºå‡†)
        2. ç»´æŠ¤ä¸¤å¥—æ—¶é—´è½´ï¼šSystemTime ç”¨äºè®¡ç®—æ€§èƒ½å»¶è¿Ÿï¼ŒPTS ç”¨äºå‰ç«¯è§†è§‰åŒæ­¥
        3. å¢åŠ äº† 'ç†”æ–­æœºåˆ¶' åº”å¯¹ç½‘ç»œä¸¢åŒ…
        """
        # --- 1. å®Œæ•´æ€§æ£€æŸ¥ (ç†”æ–­æœºåˆ¶) ---
        # å¦‚æœå½“å‰å¸§å’Œä¸Šä¸€å¸§çš„ PTS å·®å€¼è¿‡å¤§ï¼ˆä¾‹å¦‚è¶…è¿‡ 0.5ç§’ï¼‰ï¼Œè¯´æ˜ä¸­é—´å‘ç”Ÿäº†ä¸¥é‡ä¸¢åŒ…æˆ–å¡é¡¿
        # æ­¤æ—¶å¿…é¡»æ¸…ç©ºç¼“å†²åŒº
        if len(self.pts_buffer) > 0:
            # 90000 æ˜¯å¸¸è§çš„è§†é¢‘æ—¶é’Ÿé¢‘ç‡ï¼Œ0.5ç§’çº¦ç­‰äº 45000
            # è¿™é‡Œçš„é˜ˆå€¼å¯ä»¥æ ¹æ®å®é™… fps è°ƒæ•´ï¼Œæ¯”å¦‚ fps=30ï¼Œå¸§é—´éš” 3000ï¼Œé˜ˆå€¼è®¾ä¸º 15000 (5å¸§ä¸¢åŒ…)
            time_gap = pts - self.pts_buffer[-1]
            if time_gap > 45000: 
                logger.warning(f"âš ï¸ [Flow Break] æ£€æµ‹åˆ°æ—¶é—´æ–­å±‚ ({time_gap} ticks), é‡ç½® Chunk")
                self.chunk_buffer.clear()
                self.timestamp_buffer.clear()
                self.pts_buffer.clear()

        # --- 2. æ•°æ®å…¥é˜Ÿ ---
        try:
            img = frame.to_ndarray(format="bgr24")
        except Exception as e:
            logger.error(f"Frame conversion failed: {e}")
            return None
        
        self.chunk_buffer.append(img)
        self.timestamp_buffer.append(time.time()) # System Time: ç”¨äºè®¡ç®— D_an (å»¶è¿Ÿ)
        self.pts_buffer.append(pts)               # RTP PTS: ç”¨äºå‰ç«¯ <video> åŒæ­¥
        
        self.frame_count += 1
        
        # --- 3. Chunking ç­–ç•¥ ---
        target_size = self.config['chunk_size']
        stride = self.config['stride']
        
        should_infer = (len(self.chunk_buffer) >= target_size) and \
                       (self.frame_count % stride == 0)
        
        if not should_infer:
            return None 

        # --- 4. å¼€å§‹æ¨ç† ---

        # *æ¨¡æ‹Ÿç½‘ç»œæŠ–åŠ¨
        jitter = random.uniform(0.03, 0.1) 
        time.sleep(jitter)


        infer_start = time.time()
        
        # é€‰å–æœ€å…·ä»£è¡¨æ€§çš„ä¸€å¸§ (é€šå¸¸æ˜¯ Chunk çš„æœ€åä¸€å¸§ï¼Œä¹Ÿå°±æ˜¯æœ€æ–°çš„ä¸€å¸§)
        target_img = self.chunk_buffer[-1] 
        target_pts = self.pts_buffer[-1]     # <--- å…³é”®ï¼šè¿™æ˜¯è¿™å¸§ç”»é¢çš„"èº«ä»½è¯"
        
        results = self.model(target_img, verbose=False)

        # !äººä¸ºæ³¨å…¥é¢å¤–å»¶è¿Ÿï¼Œç”¨äºæ¨¡æ‹Ÿé«˜è´Ÿè½½/é«˜å»¶è¿Ÿåœºæ™¯
        # self._apply_simulated_delay()
        
        infer_end = time.time()

        fps = 0
        if self.last_infer_time > 0:
            delta = infer_end - self.last_infer_time
            if delta > 0:
                fps = 1.0 / delta
        self.last_infer_time = infer_end
        
        # --- 5. ç§‘ç ”æŒ‡æ ‡è®¡ç®— ---
        # D_an: ä» Chunk ç¬¬ä¸€å¸§åˆ°è¾¾æœåŠ¡å™¨(SystemTime) åˆ° æ¨ç†ç»“æŸ(SystemTime)
        # è¿™ä»£è¡¨äº†ç”¨æˆ·æ„ŸçŸ¥çš„"æœåŠ¡å™¨å¤„ç†æ€»è€—æ—¶" (å«æ’é˜Ÿç­‰å¾…æ—¶é—´)
        chunk_arrival_time = self.timestamp_buffer[0]
        d_an = (infer_end - chunk_arrival_time) * 1000
        
        # æ”¶é›†ç»“æœ
        detections = []
        mean_conf = 0
        if results:
            for box in results[0].boxes:
                conf = float(box.conf[0].cpu().numpy())
                mean_conf += conf
                detections.append({
                    "label": self.model.names[int(box.cls[0])],
                    "bbox": box.xyxy[0].cpu().numpy().astype(int).tolist(),
                    "confidence": round(conf, 2)
                })
            if len(results[0].boxes) > 0:
                mean_conf /= len(results[0].boxes)

        # æ¨ç†å®Œæˆåï¼Œæ ¹æ® Stride æ»‘åŠ¨çª—å£
        # å¦‚æœæ˜¯å®æ—¶æ€§ä¼˜å…ˆï¼Œé€šå¸¸æ¨ç†å®Œå°±æ¸…ç©ºï¼Œæˆ–è€…åªä¿ç•™ååŠéƒ¨åˆ†
        # è¿™é‡Œæ¼”ç¤ºç®€å•æ¸…ç©º
        self.chunk_buffer.clear()
        self.timestamp_buffer.clear()
        self.pts_buffer.clear()




        return {
            "type": "ai_result",
            "frame_id": self.frame_count,      # ä»…ä¾›è°ƒè¯•ç”¨çš„è®¡æ•°å™¨

            "pts": target_pts,                 # 1. è§†é¢‘èº«ä»½è¯ (ç”¨äºç”»æ¡†åŒæ­¥)
            "send_time": infer_end * 1000,     # 2. å‘é€æ—¶é—´æˆ³ (æ¯«ç§’ï¼Œç”¨äºå‰ç«¯ç®—å»¶è¿Ÿ)
            
            # --- [ä¸¥è°¨åŒæ­¥çš„æ ¸å¿ƒ] ---
            "timestamp": target_pts,           # RTP PTS (ä¾‹å¦‚ 23481902)
            "time_base_num": time_base.numerator,
            "time_base_den": time_base.denominator,
            
            # --- [ç§‘ç ”æ•°æ®] ---
            "d_an": round(d_an, 2),            # å…¨é“¾è·¯æœåŠ¡å™¨å»¶è¿Ÿ
            "mean_confidence": round(mean_conf, 4),
            "fps": round(fps, 1),              # 3. è¡¥å…¨ FPS
            "inference_time": round((infer_end - infer_start) * 1000, 2),
            "process_time": round((infer_end - chunk_arrival_time) * 1000, 2), # æ€»å¤„ç†è€—æ—¶
            "objects": detections
            
        }
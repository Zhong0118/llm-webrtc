# backend/ai_processor.py
import time
import logging
import numpy as np
import torch
from ultralytics import YOLO

logger = logging.getLogger("AIProcessor")

class AIProcessor:
    def __init__(self):
        self.frame_count = 0
        
        # 1. åŠ è½½æ¨¡å‹ (è‡ªåŠ¨ä¸‹è½½ yolov8n.pt)
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        logger.info(f"ğŸš€ Loading YOLO model on {self.device}...")
        try:
            self.model = YOLO('yolov8n.pt') 
            self.model.to(self.device)
            # é¢„çƒ­
            self.model(np.zeros((640, 640, 3), dtype=np.uint8), verbose=False)
            logger.info("âœ… YOLO model loaded successfully")
        except Exception as e:
            logger.error(f"âŒ Failed to load YOLO: {e}")
            self.model = None

        # FPS è®¡ç®—ç›¸å…³
        self.fps_start_time = time.time()
        self.fps_frame_counter = 0
        self.current_fps = 0.0

    def process(self, frame):
        """
        frame: aiortc çš„ VideoFrame å¯¹è±¡
        """
        total_start = time.time()
        self.frame_count += 1
        self.fps_frame_counter += 1
        
        # --- 1. è®¡ç®— FPS ---
        now = time.time()
        if now - self.fps_start_time >= 1.0:
            self.current_fps = self.fps_frame_counter / (now - self.fps_start_time)
            self.fps_frame_counter = 0
            self.fps_start_time = now

        if self.model is None:
            return {"error": "Model not loaded"}

        # --- 2. æ ¼å¼è½¬æ¢ (YUV -> BGR) ---
        # WebRTC frame è½¬ä¸º OpenCV æ ¼å¼
        img = frame.to_ndarray(format="bgr24")
        
        # --- 3. YOLO æ¨ç† ---
        infer_start = time.time()
        # imgsz=640 æ˜¯æ ‡å‡†å°ºå¯¸ï¼Œå¦‚æœä½ åŒå­¦ç”¨ 320 è§‰å¾—å¿«ï¼Œä½ ä¹Ÿå¯ä»¥æ”¹è¿™é‡Œ
        results = self.model(img, imgsz=640, conf=0.4, verbose=False)
        infer_end = time.time()
        
        inference_time_ms = (infer_end - infer_start) * 1000
        
        # --- 4. è§£æç»“æœ ---
        detections = []
        if results:
            result = results[0]
            boxes = result.boxes
            if len(boxes) > 0:
                # æå–æ•°æ® (å‚è€ƒä½ åŒå­¦çš„é€»è¾‘)
                xyxy = boxes.xyxy.cpu().numpy()
                conf = boxes.conf.cpu().numpy()
                cls = boxes.cls.cpu().numpy().astype(int)

                for i in range(len(boxes)):
                    # è¿™é‡Œçš„ conf å·²ç»åœ¨ model å‚æ•°é‡Œè¿‡æ»¤è¿‡ä¸€æ¬¡äº†ï¼Œä½†åœ¨å¾ªç¯é‡Œå†åˆ¤æ–­ä¸€æ¬¡ä¹Ÿæ— å¦¨
                    if conf[i] < 0.4: 
                        continue
                        
                    x1, y1, x2, y2 = map(int, xyxy[i])
                    label = self.model.names[cls[i]]
                    
                    detections.append({
                        "label": label,
                        "confidence": float(conf[i]),
                        "bbox": [x1, y1, x2, y2] # å‰ç«¯ AIOverlay éœ€è¦è¿™ä¸ªæ ¼å¼
                    })

        # --- 5. è®¡ç®—æ€»è€—æ—¶ ---
        total_end = time.time()
        process_time_ms = (total_end - total_start) * 1000

        # --- 6. è¿”å›ä¸°å¯Œçš„æ•°æ® ---
        return {
            "type": "yolo_detection",
            "timestamp": total_end,         # å‘é€æ—¶é—´
            "frame_id": self.frame_count,
            "fps": round(self.current_fps, 1),         # åç«¯å¤„ç† FPS
            "inference_time": round(inference_time_ms, 1), # çº¯æ¨ç†è€—æ—¶
            "process_time": round(process_time_ms, 1),     # æ€»å¤„ç†è€—æ—¶ (å«è§£ç è½¬æ¢)
            "objects": detections
        }